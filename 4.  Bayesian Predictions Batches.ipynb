{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c385c605-f254-47c8-8726-6db0b69b40b2",
   "metadata": {},
   "source": [
    "# Bayesian MBG Predictions (batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e6cd79a-32fd-4894-8dd7-c583e8a11e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functions\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pytensor.tensor as at\n",
    "\n",
    "import uuid\n",
    "import pytensor.tensor as at\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89a092",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Geostatistical Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9b3df-09bf-413b-83ef-368d2a7019a1",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9b6f9ef-83a4-4f23-8fdc-8c771b43fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load report\n",
    "with open('temp_files/report/report.pkl', 'rb') as pickle_file:\n",
    "    report = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c344177-fc16-4d28-98ad-ca9511cfb782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 8\n"
     ]
    }
   ],
   "source": [
    "#Define the directory where the pickle files are stored\n",
    "pickle_dir = 'temp_files'\n",
    "\n",
    "target_indicator = report['Target Indicator']\n",
    "\n",
    "# Get the number of CPU cores to max out the machine in the traning stage\n",
    "num_cores = os.cpu_count()\n",
    "\n",
    "print(f\"Number of CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9113a7-fc0d-4394-8a6c-0772770197d1",
   "metadata": {},
   "source": [
    "### Load target and covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "409f213f-8414-4f03-8be9-2afee28fdbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('temp_files/selected_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fea1c0f3-3d32-47b2-81f8-02c388f71d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_features = df.columns.to_list()\n",
    "\n",
    "# Remove target_values and others\n",
    "remove_list = [target_indicator, 'geometry', 'grid_id']\n",
    "\n",
    "# Remove elements in remove_list from main_list\n",
    "selected_features = [item for item in selected_features if item not in remove_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2559d878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load coordinates from the pickle file\n",
    "with open(os.path.join(pickle_dir, 'coordinates.pkl'), 'rb') as f:\n",
    "    coordinates = pickle.load(f)\n",
    "\n",
    "# Load coordinates for observed rows from the pickle file\n",
    "with open(os.path.join(pickle_dir, 'coordinates_observed.pkl'), 'rb') as f:\n",
    "    coordinates_observed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8129a75e-3878-47ef-8df9-7d83c3cfd474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Only rows with observed target indicator\n",
    "df1 = df[~df[target_indicator].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d70c106-0aab-4bb8-9166-d16cf1efff9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Covariate matrix\n",
    "X = df1[selected_features].values\n",
    "\n",
    "# Series with the target variable observed\n",
    "response = df1[target_indicator].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0be0385-869b-4dc9-9bb0-400007dbd2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardize features and response\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "response = (response - response.mean()) / response.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6692a5-2a5c-4d64-bd1a-6de75ffcb31c",
   "metadata": {},
   "source": [
    "### Recreate the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c77e4275-d0d3-4ff6-bf02-3a818ea08a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After fitting the model\n",
    "trace_filename = 'model_trace.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ba34396-fef0-40cb-bf7e-4e4bed7b9aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the model\n",
    "idata = az.from_netcdf(trace_filename)\n",
    "\n",
    "# Re-create the model\n",
    "with pm.Model() as model:\n",
    "    # Re-create the model's priors and components\n",
    "    beta = pm.Normal('beta', mu=0, sigma=1, shape=len(selected_features))\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "    ls = pm.HalfCauchy('ls', beta=1)\n",
    "\n",
    "    D = np.sqrt(((coordinates_observed[:, None, :] - coordinates_observed[None, :, :])**2).sum(axis=-1))\n",
    "\n",
    "    K = pm.gp.cov.Matern52(2, ls=ls)\n",
    "    gp = pm.gp.Latent(cov_func=K)\n",
    "    f = gp.prior('f', X=coordinates_observed)\n",
    "\n",
    "    mu = pm.math.dot(X, beta) + f\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c0504-c686-496f-90fc-8810d74a483a",
   "metadata": {},
   "source": [
    "## Generating predictions for all grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "518e121b-3c23-4ec9-96d8-d1a336f3a950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df \n",
    "\n",
    "df2 = df2.sample(400) #temporary to make some tests\n",
    "\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Covariate matrix\n",
    "X_new = df2[selected_features].values\n",
    "\n",
    "# Standardize the new data using the same scaler fitted on the observed data\n",
    "X_new = (X_new - X_new.mean(axis=0)) / X_new.std(axis=0)\n",
    "\n",
    "# Load coordinates for the new locations\n",
    "with open(os.path.join(pickle_dir, 'coordinates_unobserved.pkl'), 'rb') as f:\n",
    "    coordinates_new = pickle.load(f)\n",
    "\n",
    "# Ensure the scaler is fitted on the same data\n",
    "#scaler = StandardScaler().fit(df1[selected_features].values)\n",
    "#X_new = scaler.transform(df2[selected_features].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e83bd58-f900-4554-875a-9bc99ec6f17b",
   "metadata": {},
   "source": [
    "### Check if the covariance matrix is PSD\n",
    "- PSD: Positive Semi-Definitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7ae0015-27f1-47b4-9cce-fd6406b70533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This function is key to diagnose what is going on inside the Gaussian process\n",
    "\n",
    "def diagnose_covariance_matrix(cov, jitter=1e-6):\n",
    "    \"\"\"\n",
    "    Diagnose potential issues with a covariance matrix and suggest possible remedies.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    cov : np.ndarray or pytensor.tensor\n",
    "        The covariance matrix to diagnose.\n",
    "    jitter : float, optional\n",
    "        The amount of jitter to add to the diagonal of the covariance matrix for stabilization.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert pytensor tensor to numpy array for diagnosis if necessary\n",
    "    if isinstance(cov, at.TensorVariable):\n",
    "        # Use pm.draw to evaluate the tensor as a NumPy array\n",
    "        cov = pm.draw(cov)\n",
    "\n",
    "    # Check for symmetry\n",
    "    if not np.allclose(cov, cov.T):\n",
    "        print(\"Warning: Covariance matrix is not symmetric.\")\n",
    "    else:\n",
    "        print(\"Covariance matrix is symmetric.\")\n",
    "\n",
    "    # Check for positive semi-definiteness using eigenvalues\n",
    "    eigvals = np.linalg.eigvalsh(cov)\n",
    "    if np.all(eigvals >= 0):\n",
    "        print(\"Covariance matrix is positive semi-definite (PSD).\")\n",
    "    elif np.all(eigvals > 0):\n",
    "        print(\"Covariance matrix is positive definite (PD).\")\n",
    "    else:\n",
    "        print(\"Covariance matrix is not positive semi-definite (non-PSD).\")\n",
    "        print(\"Eigenvalues:\")\n",
    "        print(eigvals)\n",
    "\n",
    "    # Check for small or negative eigenvalues\n",
    "    if np.any(eigvals < 0):\n",
    "        print(\"There are negative eigenvalues, indicating non-PSD matrix.\")\n",
    "    elif np.any(eigvals == 0):\n",
    "        print(\"There are zero eigenvalues, indicating the matrix is singular or nearly singular.\")\n",
    "    if np.any(eigvals < jitter):\n",
    "        print(\"Some eigenvalues are smaller than the jitter value. Consider increasing jitter.\")\n",
    "\n",
    "    # Check the condition number (ratio of max to min eigenvalue)\n",
    "    cond_number = np.linalg.cond(cov)\n",
    "    print(f\"Condition number of the matrix: {cond_number:.2e}\")\n",
    "    if cond_number > 1e10:\n",
    "        print(\"Warning: Covariance matrix is ill-conditioned (large condition number).\")\n",
    "        print(\"Consider regularization or using a different covariance function.\")\n",
    "\n",
    "    # Suggest adding jitter and re-check PSD\n",
    "    cov_with_jitter = cov + jitter * np.eye(cov.shape[0])\n",
    "    eigvals_with_jitter = np.linalg.eigvalsh(cov_with_jitter)\n",
    "    if np.all(eigvals_with_jitter >= 0):\n",
    "        print(\"Adding jitter made the covariance matrix positive semi-definite.\")\n",
    "    else:\n",
    "        print(\"Even after adding jitter, the matrix is still not positive semi-definite.\")\n",
    "\n",
    "    # Check for numerical issues using Cholesky decomposition\n",
    "    try:\n",
    "        np.linalg.cholesky(cov)\n",
    "        print(\"Cholesky decomposition succeeded: Covariance matrix is positive definite.\")\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Cholesky decomposition failed: Covariance matrix is not positive definite.\")\n",
    "\n",
    "    print(\"\\nDiagnosis Complete.\")\n",
    "\n",
    "def generate_predictions(model, coordinates_new, X_new, idata, initial_jitter=1e-6, max_attempts=5):\n",
    "    \"\"\"\n",
    "    Generate predictions for new data using a Gaussian Process model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model : pm.Model\n",
    "        The PyMC model object that contains the Gaussian Process.\n",
    "    coordinates_new : np.ndarray\n",
    "        An array of coordinates for the new data points where predictions are needed.\n",
    "    X_new : np.ndarray\n",
    "        The covariate matrix for the new data points.\n",
    "    idata : az.InferenceData\n",
    "        The InferenceData object containing posterior samples from the fitted model.\n",
    "    initial_jitter : float, optional\n",
    "        The initial jitter value to add to the covariance matrix to ensure positive definiteness.\n",
    "    max_attempts : int, optional\n",
    "        Maximum number of attempts to find a stable jitter value.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        An array of mean predictions for the new data points.\n",
    "    \"\"\"\n",
    "\n",
    "    with model:\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                jitter = initial_jitter * (10 ** attempt)\n",
    "                unique_name = \"f_pred_\" + str(uuid.uuid4())\n",
    "\n",
    "                # Generate the conditional GP with added jitter to the covariance matrix\n",
    "                f_pred = gp.conditional(unique_name, coordinates_new, jitter=jitter)\n",
    "\n",
    "                # Compute the mean of the beta samples\n",
    "                beta_mean = idata.posterior['beta'].mean(dim=(\"chain\", \"draw\")).values\n",
    "\n",
    "                # Predictive mean\n",
    "                mu_pred = pm.math.dot(X_new, beta_mean) + f_pred\n",
    "\n",
    "                # Create the covariance matrix using PyMC's Matern32\n",
    "                cov = pm.gp.cov.Matern32(coordinates_new.shape[1], ls=1.0)(coordinates_new)\n",
    "\n",
    "                # Add jitter using Pytensor's identity matrix\n",
    "                cov += jitter * at.eye(cov.shape[0])\n",
    "\n",
    "                # Symmetrize the covariance matrix to ensure symmetry\n",
    "                cov = (cov + cov.T) / 2\n",
    "\n",
    "                # Check cov_matrix before predictions\n",
    "                diagnose_covariance_matrix(cov)\n",
    "                \n",
    "                # Check for positive definiteness using Cholesky decomposition\n",
    "                _ = at.slinalg.cholesky(cov)\n",
    "\n",
    "                # If successful, proceed with prediction\n",
    "                pred_samples = pm.sample_posterior_predictive(idata, var_names=[unique_name], return_inferencedata=True)\n",
    "                return pred_samples.posterior_predictive[unique_name].mean(axis=0)\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt == max_attempts - 1:\n",
    "                    raise ValueError(f\"The covariance matrix is not positive semi-definite even after {max_attempts} attempts with increasing jitter.\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9126074-9c86-4dc6-a08f-ba65477a0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe to store predictions and other values for uncertainty calculations\n",
    "#df3 = pd.DataFrame(df2[['grid_id', 'mpi']].head(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c624d4e-84c9-454d-9413-50ae25beb641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick-up productions were we left of. \n",
    "with open('temp_files/predictions.pkl', 'rb') as pickle_file:\n",
    "    df3 = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be0f92b1-3087-4c24-8aaa-c6febe949389",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position = df3.index.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10396f41-a434-4b0a-b174-4b69ebd9162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 95% confidence level, change alpha for different confidence levels\n",
    "alpha = 0.05\n",
    "z_score = stats.norm.ppf(1 - alpha/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e503963-25e4-4c67-ac9b-900d82842177",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98c403-4f27-4c08-ba1d-443e26691317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 50)\n",
      "Covariance matrix is symmetric.\n",
      "Covariance matrix is positive semi-definite (PSD).\n",
      "Condition number of the matrix: 1.22e+06\n",
      "Adding jitter made the covariance matrix positive semi-definite.\n",
      "Cholesky decomposition succeeded: Covariance matrix is positive definite.\n",
      "\n",
      "Diagnosis Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [f_pred_06bbf3f9-2fd3-4d37-b3b2-134f6f638d49]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b194324ce060470989c0bf8fe34d0b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix is symmetric.\n",
      "Covariance matrix is positive semi-definite (PSD).\n",
      "Condition number of the matrix: 9.46e+05\n",
      "Adding jitter made the covariance matrix positive semi-definite.\n",
      "Cholesky decomposition succeeded: Covariance matrix is positive definite.\n",
      "\n",
      "Diagnosis Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [f_pred_f0d6651d-21da-45c2-91e7-011e91ae7bfc]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71b66297fee4b8eb7c2585a711b2f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix is symmetric.\n",
      "Covariance matrix is positive semi-definite (PSD).\n",
      "Condition number of the matrix: 2.95e+05\n",
      "Adding jitter made the covariance matrix positive semi-definite.\n",
      "Cholesky decomposition succeeded: Covariance matrix is positive definite.\n",
      "\n",
      "Diagnosis Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [f_pred_9b16cadc-a1fc-46d9-be50-80ba57c8c949]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1653eafd7e544348a2d4fa9a88f0c7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix is symmetric.\n",
      "Covariance matrix is positive semi-definite (PSD).\n",
      "Condition number of the matrix: 3.74e+04\n",
      "Adding jitter made the covariance matrix positive semi-definite.\n",
      "Cholesky decomposition succeeded: Covariance matrix is positive definite.\n",
      "\n",
      "Diagnosis Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [f_pred_3c75efc0-f8c6-464b-9c78-240971c7662c]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7bcf415141490e90db07c540ab3858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(start_position, len(df2), step):\n",
    "\n",
    "    r = range(i, i+step)\n",
    "\n",
    "    print(r)\n",
    "    \n",
    "    X_new_i = X_new[r]\n",
    "    \n",
    "    coordinates_new_i = coordinates_new[r]\n",
    "    \n",
    "    predictions_i = generate_predictions(model, coordinates_new_i, X_new_i, idata)\n",
    "    \n",
    "    # Extracting relevant data\n",
    "    dfi = df2.loc[r][['grid_id', target_indicator]]\n",
    "    dfpi = pd.DataFrame(predictions_i)\n",
    "    \n",
    "    # Calculating mean, standard deviation, and other statistics\n",
    " \n",
    "    dfi[target_indicator] = dfpi.mean().values  # Mean prediction for each observation\n",
    "    dfi['std'] = dfpi.std().values              # Standard deviation for each observation\n",
    "    dfi['max'] = dfpi.max().values              # Max prediction for each observation\n",
    "    dfi['min'] = dfpi.min().values              # Min prediction for each observation\n",
    "     \n",
    "    # Calculating the margin of error for the confidence interval\n",
    "    dfi['standard_error'] = dfi['std'] / (len(dfpi)**0.5)\n",
    "    dfi['margin_of_error'] = z_score * dfi['standard_error']\n",
    "    \n",
    "    # Calculating the confidence interval\n",
    "    dfi['ci_lower'] = dfi[target_indicator] - dfi['margin_of_error']\n",
    "    dfi['ci_upper'] = dfi[target_indicator] + dfi['margin_of_error']\n",
    "    \n",
    "    df3 = pd.concat([df3, dfi])\n",
    "\n",
    "    #Save predictions so far\n",
    "    df3.to_pickle('temp_files/predictions.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f48785-b34f-4cf3-bae5-5181afb726c8",
   "metadata": {},
   "source": [
    "### Revert normalization and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dec545b-a31d-4d1f-bda8-67713a8d8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[target_indicator+'_untransformed'] = df3[target_indicator] #Security Copy\n",
    "\n",
    "#Revert standardization\n",
    "df3[target_indicator+'_denormalized'] = functions.revert_standardization(df3[target_indicator+'_untransformed'], \n",
    "                                                                         report['Target mean'], \n",
    "                                                                         report['Target std'])\n",
    "\n",
    "#Revert transformation\n",
    "df3[target_indicator] = functions.revert_transformation(df3[target_indicator+'_denormalized'], \n",
    "                                report['Transformation Applied'],\n",
    "                                report['Target mean'], \n",
    "                                report['Target std'], \n",
    "                               report['Lambda']).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82876d73-6a69-4288-af0a-7adc94733b35",
   "metadata": {},
   "source": [
    "### Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499dd7bc-7f8d-4a21-a3d0-a98b000d7cf8",
   "metadata": {},
   "source": [
    "#### Credible Intervals\n",
    "\n",
    "Evaluate the width of the credible intervals for predictions. Narrower intervals indicate higher precision, but they should still encompass the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15257adb-34a5-4993-9505-33c1053dfcb2",
   "metadata": {},
   "source": [
    "Width of the Confidence Interval (ci_width):\n",
    "\n",
    "    This represents the range between the upper and lower bounds of the confidence interval.\n",
    "\n",
    "Absolute Confidence Interval (absolute_confidence_interval):\n",
    "\n",
    "    This is half the width of the confidence interval. It's the margin of error, representing how far the estimate could be from the true population parameter, in absolute terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e546e0d-307e-49d6-9795-02c2d7fe4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column to represent the width of the confidence interval\n",
    "df3['ci_width'] = df3['ci_upper'] - df3['ci_lower']\n",
    "\n",
    "# Adding a column to represent the absolute confidence interval (absolute margin of error)\n",
    "df3['absolute_confidence_interval'] = df3['ci_width'] / 2 #Absolute margin of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcab8b67-7aa9-493f-98be-210b199727eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['standardized_uncertainty'] = (df3['absolute_confidence_interval'] - df3['absolute_confidence_interval'].mean())  / df3['absolute_confidence_interval'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d8f503d-405d-4e20-bfa1-05f1fa33259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_pickle('temp_files/predictions_final.pkl')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "pymc_env",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
