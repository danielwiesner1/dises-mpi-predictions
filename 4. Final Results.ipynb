{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4eba559-bc90-429d-bbad-d84e43d8767a",
   "metadata": {},
   "source": [
    "## Surface and uncertainty maps from final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7749769e-54ac-4e76-8227-2c5856fe7941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, mapping\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61092407-244c-44d2-a66a-b610bcbbe6ae",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b6f9ef-83a4-4f23-8fdc-8c771b43fcba",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'temp_files/report/report.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Load report\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_files/report/report.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pickle_file:\n\u001b[1;32m      3\u001b[0m     report \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(pickle_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/pymc_env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temp_files/report/report.pkl'"
     ]
    }
   ],
   "source": [
    "#Load report\n",
    "with open('temp_files/report/report.pkl', 'rb') as pickle_file:\n",
    "    report = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d53539-359b-4f66-99b8-6babef443f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = report['Country']\n",
    "year = report['DHS survey year']\n",
    "#target_indicator = report['Target Indicator']\n",
    "target_indicator = report['Target Indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6740a-ae15-4e40-aa36-b03ac72a42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load report\n",
    "with open('temp_files/dfpi.pkl', 'rb') as pickle_file:\n",
    "    dfpi = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca905e-cd97-4ecf-814a-d4bfed55ffc7",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e5c2f-b9ae-49c6-b916-de320b275934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shape file with geographic covariates\n",
    "shape_path = os.path.join('temp_files/clipped_shape/clipped_shape.shp')\n",
    "gdf = gpd.read_file(shape_path)\n",
    "\n",
    "gdf = gdf[['grid_id', 'geometry']]\n",
    "\n",
    "#Load predictions\n",
    "with open('temp_files/predictions.pkl', 'rb') as pickle_file:\n",
    "    df = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0636f0d-ee0f-4234-9162-76814f6d0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.plot_distribution_with_statistics(pd.Series(df[target_indicator]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56178781-afe1-467b-90d7-9f01aa3aba26",
   "metadata": {},
   "source": [
    "### Revert normalization and transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0dc44-5ea5-4add-8894-719ddc369332",
   "metadata": {},
   "source": [
    "#Revert standardization\n",
    "df[target_indicator+'_denormalized'] = functions.revert_standardization(df[target_indicator], \n",
    "                                                                        report['Target mean'], \n",
    "                                                                        report['Target std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d29b97-ec13-49ce-b887-445dcc83bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scaler from the pickle file\n",
    "with open('scaler_y.pkl', 'rb') as f:\n",
    "    scaler_y = pickle.load(f)\n",
    "\n",
    "df[target_indicator+'_untransformed'] = df[target_indicator]\n",
    "\n",
    "# Use the inverse_transform method to revert to original values\n",
    "df[target_indicator+'_denormalized'] = scaler_y.inverse_transform(df[target_indicator].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "#Revert transformation\n",
    "df[target_indicator] = functions.revert_transformation(df[target_indicator+'_denormalized'], \n",
    "                                report['Transformation Applied'],\n",
    "                                report['Target mean pre transform'], \n",
    "                                report['Target std pre transform'], \n",
    "                               report['Lambda']).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e31f0-9feb-4842-9b29-f3c2d36fb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_path = os.path.join('temp_files/report', '12. Target Predictions.pdf')\n",
    "functions.plot_distribution_with_statistics(pd.Series(df[target_indicator]), picture_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f7d10a-f9a1-4dce-ae12-7a059b06d803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t1 = df[target_indicator].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734fcb9-db88-48eb-85dd-7cbd795f09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.DataFrame(t1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd339f3-c70d-44c1-bee9-3201c37d64f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the DataFrame\n",
    "table_path = os.path.join('temp_files/report/', '15. Predictions descriptive.pdf')\n",
    "title = 'Predictions descriptive statistics original scale'\n",
    "functions.df_to_pdf(t1.round(4), table_path, title=title,  show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c77b0-d5b1-4a91-8433-fc544c1773b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recalculate ci bounds without the sample size\n",
    "df['ci_upper'] = df[target_indicator+'_untransformed']+(1.96*df['std'])\n",
    "df['ci_lower'] = df[target_indicator+'_untransformed']-(1.96*df['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6282c-914d-47d4-8215-14207cf2d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize confidence interval bounds\n",
    "for i in ['ci_upper', 'ci_lower']:\n",
    "    \n",
    "    # Use the inverse_transform method to revert to original values\n",
    "    df[i+'_denormalized'] = scaler_y.inverse_transform(df[i].values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    #Revert transformation\n",
    "    df[i] = functions.revert_transformation(df[i+'_denormalized'], \n",
    "                                    report['Transformation Applied'],\n",
    "                                    report['Target mean pre transform'], \n",
    "                                    report['Target std pre transform'], \n",
    "                                    report['Lambda']).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b4ba4-7a1f-484c-bfeb-a3553900f14d",
   "metadata": {},
   "source": [
    "### Merge with gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d4c5f5-6d78-4488-8858-b21d33f40c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.merge(df[['grid_id', target_indicator, 'ci_lower', 'ci_upper']], how='left', on='grid_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf03098-b778-444e-b897-bcd824ce9adc",
   "metadata": {},
   "source": [
    "### Surface maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0097ac47-e928-4658-bf36-1a43237d273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the GeoDataFrame with a colormap based on the target_indicator\n",
    "gdf.plot(ax=ax, column=target_indicator, cmap='viridis', alpha=0.8)\n",
    "\n",
    "# Customize the plot (optional)\n",
    "ax.set_title(f'DHS Modeled Surface for {target_indicator}')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Plot again with a legend\n",
    "gdf_plot = gdf.plot(ax=ax, column=target_indicator, cmap='viridis', alpha=0.5)\n",
    "\n",
    "# Add a color bar\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=gdf[target_indicator].min(), vmax=gdf[target_indicator].max()))\n",
    "sm._A = []  # Create an empty array for the scalar mappable\n",
    "cbar = fig.colorbar(sm, ax=ax, shrink=0.5)  # Adjust the 'shrink' parameter to reduce color bar size\n",
    "\n",
    "\n",
    "# Save the plot as a PDF\n",
    "plt.savefig(os.path.join('temp_files/report', \n",
    "                         f'16. {country} - {year} -  {target_indicator} Predictions.pdf'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d0daf-4c26-4b8d-bb0f-382b736a161f",
   "metadata": {},
   "source": [
    "### Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c9b9c-e599-4567-beb5-15963a36a34e",
   "metadata": {},
   "source": [
    "#### Credible Intervals\n",
    "\n",
    "Evaluate the width of the credible intervals for predictions. Narrower intervals indicate higher precision, but they should still encompass the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d96cc-952c-4768-9535-3a9868ff0d45",
   "metadata": {},
   "source": [
    "Width of the Confidence Interval (ci_width):\n",
    "\n",
    "    This represents the range between the upper and lower bounds of the confidence interval.\n",
    "\n",
    "Absolute Confidence Interval (absolute_confidence_interval):\n",
    "\n",
    "    This is half the width of the confidence interval. It's the margin of error, representing how far the estimate could be from the true population parameter, in absolute terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c74cac1-bcc9-4fe9-9d31-20499cc64478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column to represent the absolute confidence interval (absolute margin of error)\n",
    "\n",
    "gdf['ci_width'] = abs(gdf['ci_upper'] - gdf['ci_lower'])\n",
    "# Adding a column to represent the width of the confidence interval\n",
    "\n",
    "gdf['absolute_confidence_interval'] = gdf['ci_width'] / 2 #Absolute margin of error\n",
    "\n",
    "gdf['standardized_uncertainty'] = (gdf['absolute_confidence_interval'] - gdf['absolute_confidence_interval'].mean())  / gdf['absolute_confidence_interval'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb933b9-27ed-42ce-ad58-a4f7d0bc9e80",
   "metadata": {},
   "source": [
    "### Uncertainty maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c549508-53e2-4bdf-9437-1a0a634a37d3",
   "metadata": {},
   "source": [
    "Generate maps of prediction uncertainty to visualize areas of high and low certainty in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082ba90-f6e6-45aa-8015-956311f75425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the GeoDataFrame with a colormap based on the target_indicator\n",
    "gdf.plot(ax=ax, column=target_indicator, cmap='viridis', alpha=0.8)\n",
    "\n",
    "# Customize the plot (optional)\n",
    "ax.set_title(f'DHS Modeled Surface Uncertainty for {target_indicator}')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Plot again with a legend\n",
    "gdf_plot = gdf.plot(ax=ax, column='standardized_uncertainty', cmap='viridis', alpha=0.5)\n",
    "\n",
    "# Add a color bar\n",
    "sm = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=gdf['standardized_uncertainty'].min(), vmax=gdf['standardized_uncertainty'].max()))\n",
    "sm._A = []  # Create an empty array for the scalar mappable\n",
    "cbar = fig.colorbar(sm, ax=ax, shrink=0.5)  # Adjust the 'shrink' parameter to reduce color bar size\n",
    "\n",
    "# Add a note to the plot\n",
    "note_text = 'Std Uncertainty = SUM(Absolute Confindence Interval (ACI)i - ACI_mean / ACI_std)'\n",
    "\n",
    "ax.text(0.5, -0.3, note_text, transform=ax.transAxes, fontsize=12, color='gray', \n",
    "        ha='center', va='center', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "# Save the plot as a PDF\n",
    "plt.savefig(os.path.join('temp_files/report', \n",
    "                         f'17. {country} - {year} -  {target_indicator} Predictions Uncertainty.pdf'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d6d69-f567-484c-aae4-807a16656077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparte to original distribution\n",
    "gdf1 = pd.read_pickle('temp_files/selected_features.pkl')\n",
    "\n",
    "selected_features = gdf1.columns.to_list()\n",
    "\n",
    "# Remove target_values and others\n",
    "remove_list = [target_indicator, 'geometry', 'grid_id']\n",
    "\n",
    "# Remove elements in remove_list from main_list\n",
    "selected_features = [item for item in selected_features if item not in remove_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ce0b5-c4b1-4c31-bf0f-88664fab4c91",
   "metadata": {},
   "source": [
    "## Precision test (unseen observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a3a0b-5403-4806-b555-b3508d7d7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train subsample used\n",
    "gdf_sample = pd.read_pickle('temp_files/selected_features.pkl')\n",
    "#Load full dataset\n",
    "gdf_full = pd.read_pickle('temp_files/selected_features_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8677a54-25be-4742-bcb6-4094bdad1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only observed from train\n",
    "df1 = gdf_sample[~gdf_sample[target_indicator].isnull()]\n",
    "ids_trained_on = df1['grid_id'].to_list()\n",
    "\n",
    "#Only test \n",
    "gdf_test = gdf_full[~gdf_full['grid_id'].isin(gdf_sample['grid_id'].to_list())]\n",
    "\n",
    "#All rows with observed target\n",
    "df2 = gdf_full[~gdf_full[target_indicator].isnull()]\n",
    "\n",
    "#Rows with observed target not trained on (test set)\n",
    "df_test = df2[~df2['grid_id'].isin(ids_trained_on)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c7f34-6f8c-4a9e-b558-a2bb0849abca",
   "metadata": {},
   "source": [
    "#### Create a precisión report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d573e6c-ce84-4bbd-8d40-1ae09237951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_report = {}\n",
    "\n",
    "train_proportion = len(gdf_sample)/len(gdf_full)\n",
    "\n",
    "test_proportion = len(gdf_test)/len(gdf_full)\n",
    "\n",
    "precision_report['Train / Test Split'] = f'{round(train_proportion, 4)} / {round(test_proportion, 4)}' \n",
    "\n",
    "precision_report['Observations Trained On'] = len(df1)\n",
    "\n",
    "precision_report['Observations Tested On'] = len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd95c05-e527-4cb6-ba1f-aaf2753b81b0",
   "metadata": {},
   "source": [
    "#### Compare values to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630d61d-d5e5-4914-a5d4-816e9008dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions for test\n",
    "gdf_pred = gdf[gdf['grid_id'].isin(df_test['grid_id'].to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597a9f3-f934-4a49-bf2f-31c302b16aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on 'grid_id'\n",
    "df_merged = pd.merge(gdf_pred, df_test, on='grid_id', suffixes=('_pred', '_actual'))\n",
    "\n",
    "# Extract necessary columns\n",
    "y_sim = df_merged['mpi_pred']  # Predictions (from your prediction dataframe)\n",
    "y_obs = df_merged['mpi_actual']  # Observed values (from your actual dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f3697-cf20-40ce-9a33-f8e8cd6c8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "absolute_errors = np.abs(y_obs - y_sim)\n",
    "\n",
    "# Calculate the Mean Absolute Error\n",
    "mae = np.mean(absolute_errors)\n",
    "\n",
    "print(f\"Mean Absolute Error: {round(mae,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b322515-af7e-4785-af68-cb2b03a9850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_report[\"Predictions Mean Absolute Error\"] = round(mae, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410e371-e377-4f41-a0c5-0100bca5013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the squared errors\n",
    "squared_errors = np.square(y_obs - y_sim)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = np.mean(squared_errors)\n",
    "\n",
    "# Calculate the Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {round(rmse,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a1b4d-9f05-4513-9ed7-a87bb4a05bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_report[\"Predictions Root Mean Squared Error\"] = round(rmse,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204d3a3-162b-403d-82be-62042f3e039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_obs - y_sim\n",
    "\n",
    "# Create residual plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(np.arange(len(y_obs)), residuals, alpha=0.7)\n",
    "plt.axhline(0, color='red', linestyle='--', label='Zero Error Line')\n",
    "plt.xlabel('Data Point Index')\n",
    "plt.ylabel('Residuals (Observed - Predicted)')\n",
    "title = 'Residual Plot - Predictions vs. Observations'\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as a PDF\n",
    "plt.savefig(os.path.join('temp_files/report', \n",
    "                         f'18. {country} - {year} -  {target_indicator} {title}.pdf'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953169d9-11ce-4be9-b04e-e55ecddabbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(y_obs, y_sim, alpha=0.7, label='Predictions')\n",
    "plt.plot([min(y_obs), max(y_obs)], [min(y_obs), max(y_obs)], 'r--', label='Perfect Prediction Line')\n",
    "plt.xlabel('Observed Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "title = 'Scatter Plot - Predictions vs. Observations'\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as a PDF\n",
    "plt.savefig(os.path.join('temp_files/report', \n",
    "                         f'19. {country} - {year} -  {target_indicator} {title}.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1c142-f6dc-4b86-99a8-790a0e49881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(residuals, bins=20, alpha=0.7)\n",
    "plt.axvline(0, color='red', linestyle='--', label='Zero Error Line')\n",
    "plt.xlabel('Residuals (Observed - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "title = 'Histogram of Residuals'\n",
    "plt.title(title)\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as a PDF\n",
    "plt.savefig(os.path.join('temp_files/report', \n",
    "                         f'20. {country} - {year} -  {target_indicator} {title}.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5a7c8-ac50-4625-96ff-d050faef352e",
   "metadata": {},
   "source": [
    "### Precision Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457c0f8-dcfb-44c1-ae28-1a315da56173",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_report['Target mean pre transform'] = report['Target mean pre transform'] \n",
    "precision_report['Target std pre transform'] = report['Target std pre transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e18f9-ad8e-4369-b903-6036ac581dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr = pd.DataFrame.from_dict(data=precision_report, columns = ['Value'], orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae369a07-288e-4923-8bf9-b1c25a164fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the precison repot\n",
    "table_path = os.path.join('temp_files/report/', '20. Predictions precision report.pdf')\n",
    "title = 'Predictions Precision Report'\n",
    "functions.df_to_pdf(tpr.round(4), table_path, title=title,  show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984ecc5a-ae07-4fc8-b477-cbb9e1070aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffee6bbd-c7a1-482f-8e3a-2d3bd70e0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'KHM'\n",
    "year = '2014'\n",
    "target_indicator = 'mpi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7609c2d0-88ce-415e-88ec-8f827c2b6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = os.path.join('compared_reports/',f'{country}-{year}-{target_indicator}-hmn')\n",
    "source_path = 'temp_files/report/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61907d0a-9fbd-40c5-a000-e90f1581a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.create_pdf_report(destination_path, source_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
